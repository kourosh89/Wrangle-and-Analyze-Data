{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I did some processes of wrangling of data from Twitter account called `WeRateDogs`. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. In this report I briefly describe my wrangling efforts for this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the main stps of this project are:\n",
    "- Gathering data\n",
    "- Assessing data\n",
    "- Cleaning data\n",
    "The remaining of the project was:\n",
    "- Storing data\n",
    "- Analyzing and visualizing data\n",
    "- And finally derive insights from the analyzed clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of Wrangling data is gathering data. I needed to gather data from three different sources using three different methods.\n",
    " - The first was to manually download the WeRateDogs Twitter archive file on Udacity's website. I downloaded the file and put it in my project folder.\n",
    " - The second dataset was to programatically downloading the tweet image predictions file having the link to the file url and using Requests library.\n",
    " - The third was to use tweet IDs in Twitter archive file, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Each tweet's JSON data should be written to its own line. Then read this .txt file line by line into a pandas DataFrame with tweet ID, retweet count, favorite count, and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering all needed data I assessed data for 23 data quality and tidiness issues. The list of all issues is included in the `wrangle_act` file. The assessment was performed both visually and programatically.some of these ualities and Tidness issues found using visual. we displayed some rows of head, some rows of tail and some rows as a sample to consider dataset. Programatic assessment was performed using different tools such as .info, .value_counts(), .query, .describe(), .duplicated(), .loc, nunique(), and isin()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the qualities and Tidness issues were cleaned following three steps of define, code, and test. I started the cleaning with making a copy of each dataframe to have a backup. it san relly hepl me any time I face problem, I used this backup file. The issue was described in define step and the essential code was generated to resolve the issue in code section. The final section of test was to assure if the code worked fine and the issue was resolved completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I merged All three cleaned dataframes into a master dataframe as twitter_archive_master.csv ant then save it in my project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing and Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used some charts to get good results about project like bar plots, histograms, pie charts. I used them to reach some insight about project and get best conclusions about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got some insights of project"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
